<html>
	<head>
		<style type="text/css">
			body{font-family: sans-serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 18px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 14px;font-weight: bold;}
			.text{width: 95%;font-size: 12px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title">MUSICAL INSTRUMENT IDENTIFICATION</div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>Kunal Dhawan, Roll No.: 150102030, Branch: ECE</p>; &nbsp; &nbsp;
				<p>N Jayanth Kumar Reddy, Roll No.: 150102035, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Nagre Amar Sheshrao, Roll No.: 150102037, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Shubham, Roll No.: 150102079, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Kumar Priyadarshi, Roll No.: 150102074, Branch: ECE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">

					<!-- Start edit here  -->
					<!--is the place where you have to write your abstract. Write a brief description about your work here. Mention the features that you have used in your work and their respective motivations.-->
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
		
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						Musical Instrument Identification by a computer has many scientific as well as practical applications such as automatic annotation of musical data, structured coding and ultimately developing a system that can understand music 
					enough to collaborate with a human in real-time performance.The goal of this project is to identify musical instruments from their audio samples using a statistical pattern-recognition technique.
						<!-- Stop edit here -->

					</div>
				</div>
				
				<div class="subsection">
					<div class="heading">1.2 Motivation</div>
					<div class="text">

						<!-- Start edit here  -->
						There are many scientific and practical applications in which musical instrument identification by  a computer would be useful.  Some of them are :
						<ul>
							<li>Automatically annotating musical multimedia data</li>
							<li>Transcribing musical performances for purposes of teaching, theoretical study, or structured coding</li>
							<li>Ultimately, developing a system that can understand music enough to collaborate with a human in real-time performance</li>
						</ul>
						By attempting to build such systems, we stand to learn a great deal about the human system we seek to emulate.

						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.3 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
						<br>Block diagram of the Musical Instrument Identification approach <br>
						<img src="Picture.png" alt="This text displays when the image is umavailable" width="680px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						[1] Giulio Agostini,Maurizio Longari and Emanuele Pollastri,"Musical Instrument Timbres Classification with Spectral Features",<i>EURASIP Journal on Applied Signal Processing 2003</i>.
						
						<br><br>[2] Keith D. Martin and Youngmoo E. Kim, "Musical instrument identification: A pattern-recognition approach",<i>Presented at the 136 th meeting of the Acoustical Society of America, October 13, 1998</i>, MIT Media Lab Machine Listening Group
Rm. E15-401, 20 Ames St., Cambridge, MA 02139. 
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.5 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						Why do different musical instruments have different sounds?<br>
Various characteristics of sound, such as loudness (related to energy) and pitch (related to frequency) determine how our brain perceives a musical instrument.
BUT, if a clarinet and a piano play notes of the same pitch and loudness, the sounds will still be quite distinct to our ears.  
What , then , discriminates the sound of a clarinet from a piano ?<br><br>

The answer is Timbre!<br>
Timbre distinguishes different types of  musical instruments, such as string instruments, wind instruments, and percussion instruments. It also enables listeners to distinguish different instruments in the same category (e.g.  a clarinet and an oboe) .<br>
Musical instruments do not vibrate at a single frequency: a given note involves vibrations at many different frequencies, often called harmonics,  partials, or overtones. The relative pitch and loudness of these overtones along with other acoustic features give the note a characteristic sound we call the timbre of the instrument.<br><br>

Timbre can be successfully used to distinguish between the 4 broad classes of music. After that we may use class-specific features to distinguish the intrument within the class.<br><br>

Thus to achieve the goal of detecting the instrument bein played in a given sound clip, we propose a two step approach: <br>
[1] In the first step we take advantage of the fact that musical instruments can be divided into 4 broad classes: Woodwind; String; Keyboard; Brass. Thus we train use a simple multilayer perceptron trained using basic timbre features : Spectral Centroid, Zero Crossing rate and Spectral Rolloff. This helps find the basic class of the given musical instrument and leaves us with the task of finding the exact instrument from within that basic class.<br>
[2] In the second step, we train a classifer with individual class specific features . This helps us to accuarately identify the musical intrument within the basic class as detected earlier.<br>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.6 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					The approach towards identification of musical instruments relies on the set of features, collectively known as "Timbre". 
					There are two broad types of features of a music signal specifying its properties:<br>
The temporal features (time domain features), which are simple to extract and have easy physical interpretation, like : the energy of signal, zero crossing rate, maximum amplitude, minimum energy, etc.
<br>The spectral features (frequency based features), which are obtained by converting the time based signal into the frequency domain using the Fourier Transform, like: fundamental frequency,  frequency components, spectral centroid, etc.
   Timbre depends primarily upon the spectral features,although it also depends upon the sound pressure and the temporal characteristics of the sound. Some of the prominent features are described below :<br>
					[1] Amplitude envelope refers to the changes in the amplitude of a sound over time, and is an influential property as it affects our perception of timbre.<br>
					[2] The zero-crossing rate is measured directly from the signal waveform as the number of sign inversions.<br>
					[3] Pitch is a perceptual property of sounds that allows their ordering on a frequency-related scale. Pitch may be quantified by frequency; "high" pitch means very rapid oscillation, and "low" pitch corresponds to slower oscillation. <br>
					A spectral envelope is a curve in the frequency-amplitude plane, derived from a fourier magnitude spectrum. It wraps tightly and smoothly around the magnitude spectrum ,linking the peaks.<br>
					[4] The Spectral Centroid is simply the centroid of the spectral envelope, and is one of the most important attributes governing timbre.<br>
					[5] Intensity – The sum of the energy in the spectral envelope approximates the instantaneous loudness of the signal. Tracking this over time leads to simple measures of amplitude modulation, which can reveal tremolo (an important feature for brass instruments). Intensity is the basis of many other spectral
					features like Spectral Rolloff frequency among others.<br>
					
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						<br>The dataset chosen for the task at hand is the audio samples taken from the University of Iowa - Electronic Music Studios .
						The samples taken belong to the three instrument families namely - String , Woodwind and Brass. There are a total of
						417 samples of which a 80 % - 20 % division has been done to be used for training and testing, respectively.<br>
						<br> The link to the dataset is here : <a href="http://theremin.music.uiowa.edu/MISPost2012Intro.html"> University of Iowa : Audio Samples Site</a>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						[1] In the first stage of the experiment, A neural network classifier was trained using three basic features i.e. Zero Crossing Rate,
						Spectral Centroid and Spectral RollOff Frequency , for identifying the instrument family.<br>
						The neural network was trained with dropout, and Adam Optimizer was used in training the classifier. The classifier was trained for 500 epochs and the respective training and 
						testing scores were evaluated.<br>
						<ul>
							<li>Training Accuracy : 84.73 %</li>
							<li>Testing Accuracy :   80.72 %</li>
						</ul>
						The classifier can be further improved using more number of relevant features, which we are currently working on. Also, the size of the training
						dataset is insufficient as of now. Increasing the sample size will improve the performance of the classifier greatly.<br>
						<br>Here is a snapshot of the classifier indicating training and testing accuracies :
						<br><br><img src="Picture2.png" alt="This text displays when the image is umavailable" width="500px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
